import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik Denet√ßi Pro", layout="wide")

st.title("üîç Profesyonel Atƒ±f & Kaynak√ßa Denet√ßisi")
st.markdown("Bu s√ºr√ºmde e≈üle≈üen kaynaklar tam metin olarak Excel'e eklenir ve sayfa sonunda listelenir.")

KARA_LISTE = [
    "january", "february", "march", "april", "may", "june", "july", "august", "september", "october", "november", "december",
    "ocak", "≈üubat", "mart", "nisan", "mayƒ±s", "haziran", "temmuz", "aƒüustos", "eyl√ºl", "ekim", "kasƒ±m", "aralƒ±k",
    "india", "lockdown", "university", "school", "department", "figure", "table", "source", "adapted", "from", "although", "though"
]

uploaded_file = st.file_uploader("PDF Dosyanƒ±zƒ± Y√ºkleyin", type="pdf")

if uploaded_file:
    with st.spinner('Analiz yapƒ±lƒ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            text = page.get_text("text")
            text = re.sub(r'-\s*\n', '', text)
            text = text.replace('\n', ' ')
            full_text += text + " "
        doc.close()
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. Kaynak√ßayƒ± Bul ve Par√ßala
    ref_keywords = [r'\bKaynak√ßa\b', r'\bReferences\b', r'\bKAYNAK√áA\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:]
        
        # Kaynak√ßayƒ± tekil kaynaklara b√∂lmeye √ßalƒ±≈ü (Genellikle (Yƒ±l) veya Soyad ile ayrƒ±lƒ±r)
        # Basit bir y√∂ntem: Her kaynaƒüƒ± yazar soyadlarƒ±ndan tahmin etmeye √ßalƒ±≈üalƒ±m
        # ≈ûimdilik kar≈üƒ±la≈ütƒ±rma i√ßin kaynak√ßayƒ± c√ºmle c√ºmle veya blok blok saklayalƒ±m
        ref_blocks = re.split(r'(?=[A-Z√áƒûƒ∞√ñ≈û√ú][a-z√ßƒüƒ±√∂≈ü√º]+,\s[A-Z]\.)', raw_ref_section)

        # 2. Atƒ±f Ayƒ±klama
        found_raw = []
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append({"text": sub.strip(), "type": "Parantez ƒ∞√ßi"})
        
        inline_matches = re.finditer(r'([A-Z√áƒûƒ∞√ñ≈û√ú][a-z√ßƒüƒ±√∂≈ü√º]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append({"text": f"{m.group(1)} ({m.group(2)})", "type": "Metin ƒ∞√ßi"})

        results = []
        for item in found_raw:
            raw_text = item["text"]
            if any(word.lower() in raw_text.lower().split() for word in KARA_LISTE):
                continue
            
            year_match = re.search(r'\d{4}', raw_text)
            if not year_match: continue
            year = year_match.group()
            
            authors = re.findall(r'[A-Z√áƒûƒ∞√ñ≈û√ú][a-z√ßƒüƒ±√∂≈ü√º]+|[A-Z√áƒûƒ∞√ñ≈û√ú]{2,}', raw_text)
            authors = [a for a in authors if len(a) > 2]
            
            if authors:
                matched_ref_text = "Bulunamadƒ±"
                is_found = False
                
                # Kaynak√ßada bu atƒ±fƒ±n tam metnini ara
                for block in ref_blocks:
                    if any(a.lower() in block.lower() for a in authors) and year in block:
                        matched_ref_text = block.strip()
                        is_found = True
                        break
                
                results.append({
                    "Metindeki Atƒ±f": raw_text,
                    "Yazarlar": ", ".join(authors),
                    "Yƒ±l": year,
                    "Durum": "‚úÖ Var" if is_found else "‚ùå Yok",
                    "Kaynak√ßadaki Tam Metni": matched_ref_text
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki Atƒ±f'])

        # 3. Aray√ºz ve Excel
        st.subheader("üìä Atƒ±f ve Kaynak√ßa Kar≈üƒ±la≈ütƒ±rma Tablosu")
        st.dataframe(df_res, use_container_width=True)
        
        # Excel
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("üì• Excel Raporunu ƒ∞ndir", output.getvalue(), "atik_kaynakca_denetimi.xlsx")

        # 4. Sayfa Altƒ±na T√ºm Kaynak√ßayƒ± Listele
        st.divider()
        st.subheader("üìö Tespit Edilen Kaynak√ßa Listesi")
        with st.expander("T√ºm Kaynak√ßayƒ± G√∂r√ºnt√ºle"):
            for i, block in enumerate(ref_blocks):
                if len(block.strip()) > 10:
                    st.write(f"**[{i}]** {block.strip()}")
    else:
        st.error("Kaynak√ßa b√∂l√ºm√º tespit edilemedi.")
