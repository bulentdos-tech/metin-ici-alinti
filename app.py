import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” KesinleÅŸtirilmiÅŸ AtÄ±f & KaynakÃ§a DenetÃ§isi")
st.markdown("Kurumsal raporlar (VNIT, IIM vb.) ve gazete haberleri iÃ§eren karmaÅŸÄ±k kaynakÃ§alar iÃ§in optimize edildi.")

# Filtre: AtÄ±f olmayan kelimeleri temizle
KARA_LISTE = ["march", "april", "may", "june", "july", "august", "india", "university", "journal", "source", "table", "figure"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Derinlemesine analiz yapÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            text = page.get_text("text")
            text = text.replace('\n', ' ') # SatÄ±r sonlarÄ±nÄ± kaldÄ±r
            full_text += text + " "
        doc.close()
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ Bul
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:]
        
        # --- KAYNAKÃ‡A PARÃ‡ALAMA (YENÄ° STRATEJÄ°) ---
        # KaynakÃ§ayÄ± "EriÅŸim Tarihi" veya "Nokta + BoÅŸluk + BÃ¼yÃ¼k Harf" gibi kalÄ±plardan bÃ¶lÃ¼yoruz
        # VNIT ve Badger gibi farklÄ± tÃ¼rleri birbirinden ayÄ±rmak iÃ§in:
        ref_blocks = re.split(r'(?<=\(Accessed [A-Za-z]+ \d{1,2}, \d{4}\)\.)|(?<=\d{4}\.)', raw_ref_section)
        ref_blocks = [b.strip() for b in ref_blocks if len(b.strip()) > 30]

        # 2. AtÄ±f AyÄ±klama
        found_raw = []
        # Parantez iÃ§i (Ahmed, 2020)
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append(sub.strip())
        
        # Metin iÃ§i Ahmed (2020)
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append(f"{m.group(1)} ({m.group(2)})")

        results = []
        for item in found_raw:
            if any(word in item.lower() for word in KARA_LISTE): continue
            
            year_match = re.search(r'\d{4}', item)
            if not year_match: continue
            year = year_match.group()
            
            # YazarlarÄ±/KurumlarÄ± bul (VNIT, Ahmed, Badger vb.)
            # Hem normal isimleri hem de VNIT gibi bÃ¼yÃ¼k harfli kÄ±saltmalarÄ± yakala
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ]{2,}|[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', item)
            authors = [a for a in authors if a.lower() not in KARA_LISTE and len(a) > 1]
            
            if authors:
                matched_full_ref = "âŒ BULUNAMADI"
                is_found = False
                
                # KaynakÃ§a bloklarÄ±nda Ã§apraz ara
                for block in ref_blocks:
                    # AtÄ±ftaki anahtar kelimelerden biri ve yÄ±l kaynakÃ§ada geÃ§iyor mu?
                    if any(a.lower() in block.lower() for a in authors) and year in block:
                        matched_full_ref = block
                        is_found = True
                        break
                
                results.append({
                    "Metindeki AtÄ±f": item,
                    "Bulunan Anahtarlar": ", ".join(authors),
                    "YÄ±l": year,
                    "Durum": "âœ… Var" if is_found else "âŒ Yok",
                    "Tam KaynakÃ§a KarÅŸÄ±lÄ±ÄŸÄ±": matched_full_ref
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki AtÄ±f'])

        # 3. SonuÃ§lar
        st.subheader("ğŸ“Š AtÄ±f & KaynakÃ§a EÅŸleÅŸme Analizi")
        st.dataframe(df_res, use_container_width=True)
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ Excel Raporunu Ä°ndir", output.getvalue(), "akademik_denetim.xlsx")

        st.divider()
        st.subheader("ğŸ“š Sistem TarafÄ±ndan TanÄ±mlanan Kaynaklar")
        for b in ref_blocks:
            st.info(b)
    else:
        st.error("KaynakÃ§a bÃ¶lÃ¼mÃ¼ bulunamadÄ±.")
