import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” Profesyonel AtÄ±f DenetÃ§isi (HatasÄ±z SÃ¼rÃ¼m)")
st.markdown("Bu sÃ¼rÃ¼m, kaynakÃ§adaki bir ismi sadece **metin gÃ¶vdesinde** arar; kaynakÃ§anÄ±n kendisini tarama dÄ±ÅŸÄ± bÄ±rakÄ±r.")

KARA_LISTE = ["march", "april", "university", "journal", "retrieved", "from", "doi", "http", "https", "pdf", "page", "january", "study", "research"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Derinlemesine analiz yapÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            full_text += page.get_text("text") + " \n "
        doc.close()
        # Metin temizleme
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ AyÄ±r (Arama alanÄ±nÄ± kÄ±sÄ±tlamak iÃ§in kritik)
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        # Sadece kaynakÃ§adan Ã¶nceki metin
        body_text = full_text[:split_index]
        # Sadece kaynakÃ§a metni
        raw_ref_section = full_text[split_index:]
        
        # KaynakÃ§ayÄ± bloklara bÃ¶l (APA ve genel formatlar iÃ§in optimize edildi)
        ref_pattern = r'(?<=\d{4}[a-z]?\)\. )|(?<=\.\s)(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+,?\s+[A-Z]\.)'
        ref_blocks = [b.strip() for b in re.split(ref_pattern, raw_ref_section) if len(b.strip()) > 15]

        # --- ANALÄ°Z 1: METÄ°NDE VAR, KAYNAKÃ‡ADA YOK ---
        found_in_body = []
        # Parantez iÃ§i: (Yazar, 2020)
        paren_matches = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_matches:
            for sub in group.split(';'):
                found_in_body.append(sub.strip())
        
        # Metin iÃ§i: Yazar (2020)
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_in_body.append(f"{m.group(1)} ({m.group(2)})")

        text_to_ref_errors = []
        for item in found_in_body:
            if any(word in item.lower() for word in KARA_LISTE): continue
            year_m = re.search(r'\d{4}', item)
            if not year_m: continue
            year = year_m.group()
            
            # YazarÄ± Ã§ek (Ã–rn: "Zhai" veya "Biggs")
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', item)
            if authors:
                main_author = authors[0]
                # SADECE kaynakÃ§a bloklarÄ± iÃ§inde ara
                is_in_ref = any(main_author.lower() in block.lower() and year in block for block in ref_blocks)
                if not is_in_ref:
                    text_to_ref_errors.append({"Tespit Edilen AtÄ±f": item})

        df_missing_in_ref = pd.DataFrame(text_to_ref_errors).drop_duplicates()

        # --- ANALÄ°Z 2: KAYNAKÃ‡ADA VAR, METÄ°NDE YOK (Burada sildiÄŸiniz kaynaklar Ã§Ä±kmalÄ±) ---
        ref_to_text_errors = []
        for block in ref_blocks:
            # KaynakÃ§a bloÄŸundan ilk yazar ve yÄ±lÄ± bul
            author_match = re.search(r'^([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)', block)
            year_match = re.search(r'(\d{4})', block)
            
            if author_match and year_match:
                author = author_match.group(1)
                year = year_match.group(1)
                
                # KRÄ°TÄ°K: Sadece body_text (metin gÃ¶vdesi) iÃ§inde ara!
                # (Yazar, 2020) veya Yazar (2020) kalÄ±plarÄ±nÄ± kontrol et
                cit_pattern = rf"{author}.*?{year}|{year}.*?{author}"
                is_cited_in_body = re.search(cit_pattern, body_text, re.IGNORECASE)
                
                if not is_cited_in_body:
                    ref_to_text_errors.append({"AtÄ±fÄ± Olmayan Kaynak": block[:120] + "..."})

        df_unused_refs = pd.DataFrame(ref_to_text_errors)

        # --- SONUÃ‡ EKRANI ---
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("âŒ KaynakÃ§ada Bulunmayan AtÄ±flar")
            if not df_missing_in_ref.empty:
                st.error(f"{len(df_missing_in_ref)} eksik kaynak bulundu.")
                st.table(df_missing_in_ref)
            else:
                st.success("Metindeki tÃ¼m atÄ±flar kaynakÃ§ada var.")

        with col2:
            st.subheader("âš ï¸ Metinde AtÄ±fÄ± Olmayan Kaynaklar")
            if not df_unused_refs.empty:
                st.warning(f"{len(df_unused_refs)} kaynak metinde kullanÄ±lmamÄ±ÅŸ.")
                st.table(df_unused_refs)
            else:
                st.success("KaynakÃ§adaki tÃ¼m eserlere atÄ±f yapÄ±lmÄ±ÅŸ.")

        # Excel Raporu
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_missing_in_ref.to_excel(writer, sheet_name='Eksik Kaynaklar', index=False)
            df_unused_refs.to_excel(writer, sheet_name='AtÄ±fÄ± Olmayanlar', index=False)
        st.divider()
        st.download_button("ğŸ“¥ Hata Raporunu Ä°ndir", output.getvalue(), "denetim_raporu.xlsx")
    else:
        st.error("KaynakÃ§a baÅŸlÄ±ÄŸÄ± bulunamadÄ±.")
