import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” Profesyonel AtÄ±f & KaynakÃ§a DenetÃ§isi")
st.markdown("Park (2020) ve benzeri karmaÅŸÄ±k kaynakÃ§a yapÄ±larÄ± iÃ§in optimize edilmiÅŸ sÃ¼rÃ¼m.")

# Kara listeyi daralttÄ±k ve sadece kesinlikle yazar olmayacak kelimelere odaklandÄ±k
KARA_LISTE = ["march", "april", "may", "june", "july", "august", "september", "october", "november", "december",
              "india", "korea", "seoul", "china", "university", "journal", "cureus", "table", "figure"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Analiz yapÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            text = page.get_text("text")
            # SatÄ±r sonlarÄ±nÄ± boÅŸluk yap ama metni tek parÃ§a tut
            text = text.replace('\n', ' ')
            full_text += text + " "
        doc.close()
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ AyÄ±r
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:]
        
        # --- KAYNAKÃ‡A PARÃ‡ALAMA (Park 2020 Ã¶rneÄŸine Ã¶zel) ---
        # Maddeleri sadece "YÄ±l + Nokta" kombinasyonuna gÃ¶re deÄŸil, 
        # yazar dizilimlerini bozmadan daha geniÅŸ bloklar halinde ayÄ±rÄ±yoruz.
        # Bu regex, bir sonraki yazarÄ±n bÃ¼yÃ¼k olasÄ±lÄ±kla baÅŸladÄ±ÄŸÄ± yeri tahmin eder.
        ref_blocks = re.split(r'(?<=\d{4}[a-z]?\.)\s+(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)', raw_ref_section)
        ref_blocks = [b.strip() for b in ref_blocks if len(b.strip()) > 30]

        # 2. AtÄ±f AyÄ±klama
        found_raw = []
        # Parantez iÃ§i
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append(sub.strip())
        
        # Metin iÃ§i
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append(f"{m.group(1)} ({m.group(2)})")

        results = []
        for item in found_raw:
            # Filtreleme
            if any(word in item.lower() for word in KARA_LISTE): continue
            
            year_match = re.search(r'\d{4}', item)
            if not year_match: continue
            year = year_match.group()
            
            # YazarlarÄ± yakala (Sadece kelime baÅŸÄ±ndaki ana ismi al)
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', item)
            authors = [a for a in authors if a.lower() not in KARA_LISTE and len(a) > 2]
            
            if authors:
                matched_full_ref = "âŒ KAYNAKÃ‡ADA BULUNAMADI"
                is_found = False
                
                # KaynakÃ§ada Park, Ahmed, Bogoch gibi ana soyadlarÄ±nÄ± ara
                main_author = authors[0]
                for block in ref_blocks:
                    if main_author.lower() in block.lower() and year in block:
                        matched_full_ref = block
                        is_found = True
                        break
                
                results.append({
                    "Metindeki AtÄ±f": item,
                    "Ana Yazar": main_author,
                    "YÄ±l": year,
                    "Durum": "âœ… Var" if is_found else "âŒ Yok",
                    "KaynakÃ§adaki Tam KarÅŸÄ±lÄ±ÄŸÄ±": matched_full_ref
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki AtÄ±f'])

        # 3. SonuÃ§lar
        st.subheader("ğŸ“Š AtÄ±f DoÄŸrulama Raporu")
        st.dataframe(df_res, use_container_width=True)
        
        # Excel
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ Excel Raporunu Ä°ndir", output.getvalue(), "akademik_denetim.xlsx")

        # 4. KaynakÃ§a Maddeleri (Denetim iÃ§in)
        st.divider()
        st.subheader("ğŸ“š AyÄ±klanan KaynakÃ§a Maddeleri (Tam Metin)")
        for b in ref_blocks:
            st.success(b)
    else:
        st.error("KaynakÃ§a baÅŸlÄ±ÄŸÄ± bulunamadÄ±.")
