import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” KesinleÅŸtirilmiÅŸ KaynakÃ§a AyÄ±rÄ±cÄ±")
st.markdown("DOI ve URL birleÅŸmeleri (Claxton/Collins sorunu) iÃ§in Ã¶zel mantÄ±k eklendi.")

def clean_and_format(text):
    """Metni temizler ve 'References' gibi kalÄ±ntÄ±larÄ± atar."""
    text = re.sub(r'^References\s+', '', text, flags=re.IGNORECASE)
    return text.strip()

KARA_LISTE = ["march", "april", "university", "journal", "doi", "http", "https", "retrieved"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('YapÄ±ÅŸÄ±k kaynaklar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            # Sayfa geÃ§iÅŸlerinde zorunlu boÅŸluk bÄ±rakarak yapÄ±ÅŸmayÄ± engelle
            full_text += page.get_text("text") + " [PAGE_BREAK] "
        doc.close()

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ Bul
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:].replace("[PAGE_BREAK]", " ")
        
        # --- ğŸš€ KRÄ°TÄ°K AYRIÅTIRMA MANTIÄI ---
        # 1. DOI/URL sonrasÄ±ndaki bÃ¼yÃ¼k harf geÃ§iÅŸlerini bul (Ã–rn: ...876 Collins)
        # 2. Sayfa numarasÄ± sonrasÄ±ndaki bÃ¼yÃ¼k harf geÃ§iÅŸlerini bul (Ã–rn: ...362 Collins)
        # 3. Nokta + BoÅŸluk + BÃ¼yÃ¼k Harf + VirgÃ¼l dizilimini bul
        pattern = r'(?<=\d|/|[a-z])\s+(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+,?\s+[A-Z]\.)'
        ref_blocks = re.split(pattern, raw_ref_section)
        
        # Temizlik
        ref_blocks = [clean_and_format(b) for b in ref_blocks if len(b.strip()) > 20]

        # 2. AtÄ±f Analizi
        found_raw = []
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append(sub.strip())
        
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append(f"{m.group(1)} ({m.group(2)})")

        results = []
        for item in found_raw:
            if any(word in item.lower() for word in KARA_LISTE): continue
            
            year_match = re.search(r'\d{4}', item)
            if not year_match: continue
            year = year_match.group()
            
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', item)
            authors = [a for a in authors if len(a) > 2 and a.lower() not in KARA_LISTE]
            
            if authors:
                matched_full_ref = "âŒ BULUNAMADI"
                is_found = False
                main_author = authors[0]
                
                # SÄ±kÄ± Denetim: Sadece yazar isminin geÃ§tiÄŸi doÄŸru bloÄŸu al
                for block in ref_blocks:
                    if main_author.lower() in block.lower() and year in block:
                        matched_full_ref = block
                        is_found = True
                        break
                
                results.append({
                    "Metindeki AtÄ±f": item,
                    "Yazar": main_author,
                    "YÄ±l": year,
                    "Durum": "âœ… Var" if is_found else "âŒ Yok",
                    "KaynakÃ§adaki DoÄŸru KarÅŸÄ±lÄ±ÄŸÄ±": matched_full_ref
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki AtÄ±f'])

        # 3. Ã‡Ä±ktÄ±
        st.subheader("ğŸ“Š DÃ¼zeltilmiÅŸ AtÄ±f Raporu")
        st.dataframe(df_res, use_container_width=True)
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ Excel DosyasÄ±nÄ± Ä°ndir", output.getvalue(), "duzeltilmis_kaynakca.xlsx")

        with st.expander("Sistem KaynakÃ§ayÄ± NasÄ±l AyÄ±rdÄ±? (Kontrol Listesi)"):
            for i, b in enumerate(ref_blocks):
                st.write(f"**{i+1}:** {b}")
    else:
        st.error("KaynakÃ§a bulunamadÄ±.")
