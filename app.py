import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” AkÄ±llÄ± KaynakÃ§a AyrÄ±ÅŸtÄ±rÄ±cÄ± (APA 7)")
st.markdown("YapÄ±ÅŸÄ±k kaynaklar (URL/DOI sonrasÄ±ndaki birleÅŸmeler) iÃ§in geliÅŸmiÅŸ bÃ¶lme algoritmasÄ± eklendi.")

def clean_and_format(text):
    """Metni temizler ve 'References' gibi kalÄ±ntÄ±larÄ± atar."""
    text = re.sub(r'^References\s+', '', text, flags=re.IGNORECASE)
    return text.strip()

KARA_LISTE = ["march", "april", "university", "journal", "doi", "http", "https", "retrieved", "pdf"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('YapÄ±ÅŸÄ±k kaynaklar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor ve eÅŸleÅŸtiriliyor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            # Sayfa geÃ§iÅŸlerinde boÅŸluk bÄ±rakarak yapay birleÅŸmeyi Ã¶nle
            full_text += page.get_text("text") + " \n "
        doc.close()

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ Tespit Et
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:].replace("References", "")
        
        # --- ğŸš€ AKILLI MAKAS (Regex) ---
        # Bu desen: ".pdf", "DOI numarasÄ±" veya "Nokta" sonrasÄ±nda gelen 
        # "SoyadÄ±, A. (YÄ±l)" yapÄ±sÄ±nÄ± gÃ¶rÃ¼r ve oradan metni bÃ¶ler.
        pattern = r'(?<=\.pdf|\d{4}\)|\.|\d)\s+(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+,?\s+[A-Z]\.?\s*(?:&|and)?\s*[A-Z]?\.?\s*\(?\d{4}\)?)'
        ref_blocks = re.split(pattern, raw_ref_section)
        ref_blocks = [clean_and_format(b) for b in ref_blocks if len(b.strip()) > 20]

        # 2. AtÄ±f Analizi
        found_raw = []
        # Parantez iÃ§i atÄ±flar
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append(sub.strip())
        
        # Metin iÃ§i atÄ±flar (Yazar, YÄ±l)
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append(f"{m.group(1)} ({m.group(2)})")

        results = []
        for item in found_raw:
            if any(word in item.lower() for word in KARA_LISTE): continue
            
            year_match = re.search(r'\d{4}', item)
            if not year_match: continue
            year = year_match.group()
            
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', item)
            authors = [a for a in authors if len(a) > 2 and a.lower() not in KARA_LISTE]
            
            if authors:
                matched_full_ref = "âŒ KAYNAKÃ‡ADA BULUNAMADI"
                is_found = False
                main_author = authors[0]
                
                # Spesifik Blok EÅŸleÅŸtirme
                for block in ref_blocks:
                    # Blok iÃ§erisinde HEM ana yazar HEM yÄ±l geÃ§mek zorunda
                    if main_author.lower() in block.lower() and year in block:
                        matched_full_ref = block
                        is_found = True
                        break
                
                results.append({
                    "Metindeki AtÄ±f": item,
                    "Ana Yazar": main_author,
                    "YÄ±l": year,
                    "Durum": "âœ… Var" if is_found else "âŒ Yok",
                    "KaynakÃ§adaki KarÅŸÄ±lÄ±ÄŸÄ±": matched_full_ref
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki AtÄ±f'])

        # 3. SonuÃ§ Tablosu ve Ä°ndirme
        st.subheader("ğŸ“Š GeliÅŸmiÅŸ AtÄ±f DoÄŸrulama SonuÃ§larÄ±")
        st.dataframe(df_res, use_container_width=True
