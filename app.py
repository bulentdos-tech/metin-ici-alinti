import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” KesinleÅŸtirilmiÅŸ AtÄ±f & KaynakÃ§a DenetÃ§isi")
st.markdown("Bu sÃ¼rÃ¼mde kaynakÃ§a parÃ§alama mantÄ±ÄŸÄ± optimize edildi ve Excel Ã§Ä±ktÄ±sÄ± gÃ¼Ã§lendirildi.")

KARA_LISTE = [
    "january", "february", "march", "april", "may", "june", "july", "august", "september", "october", "november", "december",
    "ocak", "ÅŸubat", "mart", "nisan", "mayÄ±s", "haziran", "temmuz", "aÄŸustos", "eylÃ¼l", "ekim", "kasÄ±m", "aralÄ±k",
    "india", "lockdown", "university", "school", "department", "figure", "table", "source", "adapted", "from", "although", "though"
]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Analiz yapÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            text = page.get_text("text")
            text = re.sub(r'-\s*\n', '', text)
            text = text.replace('\n', ' [NL] ') # SatÄ±r sonlarÄ±nÄ± iÅŸaretle (ayrÄ±ÅŸtÄ±rma iÃ§in)
            full_text += text + " "
        doc.close()
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ Tespit Et
    ref_keywords = [r'KaynakÃ§a', r'References', r'KAYNAKÃ‡A', r'REFERENCES', r'Kaynaklar']
    split_index = -1
    for kw in ref_keywords:
        # Kelime sÄ±nÄ±rÄ± olmadan ara (bitiÅŸik yazÄ±lmÄ±ÅŸ olabilir)
        match = re.search(kw, full_text)
        if match:
            # Genelde kaynakÃ§a sondadÄ±r, son eÅŸleÅŸmeyi bulalÄ±m
            all_matches = list(re.finditer(kw, full_text))
            split_index = all_matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        raw_ref_section = full_text[split_index:]
        
        # KaynakÃ§ayÄ± her bir kaynak iÃ§in parÃ§alara ayÄ±r
        # Genellikle her kaynak [NL] (yeni satÄ±r) ile baÅŸlar
        ref_blocks = [b.replace('[NL]', '').strip() for b in raw_ref_section.split(' [NL] ') if len(b.strip()) > 20]

        # 2. AtÄ±f AyÄ±klama
        found_raw = []
        # Parantez iÃ§i
        paren_groups = re.findall(r'\(([^)]+\d{4}[a-z]?)\)', body_text)
        for group in paren_groups:
            for sub in group.split(';'):
                found_raw.append({"text": sub.strip(), "type": "Parantez Ä°Ã§i"})
        
        # Metin iÃ§i
        inline_matches = re.finditer(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for m in inline_matches:
            found_raw.append({"text": f"{m.group(1)} ({m.group(2)})", "type": "Metin Ä°Ã§i"})

        results = []
        for item in found_raw:
            raw_text = item["text"]
            if any(word.lower() in raw_text.lower().split() for word in KARA_LISTE):
                continue
            
            year_match = re.search(r'\d{4}', raw_text)
            if not year_match: continue
            year = year_match.group()
            
            authors = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+|[A-ZÃ‡ÄÄ°Ã–ÅÃœ]{2,}', raw_text)
            authors = [a for a in authors if len(a) > 2]
            
            if authors:
                matched_full_ref = "KAYNAKÃ‡ADA BULUNAMADI"
                is_found = False
                
                # KaynakÃ§adaki her bloÄŸu kontrol et
                for block in ref_blocks:
                    if any(a.lower() in block.lower() for a in authors) and year in block:
                        matched_full_ref = block
                        is_found = True
                        break
                
                results.append({
                    "Metindeki AtÄ±f": raw_text,
                    "Yazarlar": ", ".join(authors),
                    "YÄ±l": year,
                    "Durum": "âœ… Var" if is_found else "âŒ Yok",
                    "KaynakÃ§adaki Tam KarÅŸÄ±lÄ±ÄŸÄ±": matched_full_ref
                })

        df_res = pd.DataFrame(results).drop_duplicates(subset=['Metindeki AtÄ±f'])

        # 3. GÃ¶rselleÅŸtirme
        st.subheader("ğŸ“Š AtÄ±f & KaynakÃ§a EÅŸleÅŸme Raporu")
        st.dataframe(df_res, use_container_width=True)
        
        # Excel
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ Excel Raporunu Ä°ndir", output.getvalue(), "denetim_sonuclari.xlsx")

        # 4. KaynakÃ§a Ã–nizleme ve Liste
        st.divider()
        st.subheader("ğŸ“š AyÄ±klanan KaynakÃ§a Maddeleri")
        with st.expander("PDF'den ayrÄ±ÅŸtÄ±rÄ±lan tÃ¼m kaynaklarÄ± gÃ¶r"):
            if ref_blocks:
                for b in ref_blocks:
                    st.markdown(f"- {b}")
            else:
                st.warning("KaynakÃ§a baÅŸlÄ±ÄŸÄ± bulundu ama maddeler ayrÄ±ÅŸtÄ±rÄ±lamadÄ±.")
                st.text("Ham Metin Ã–nizlemesi:")
                st.write(raw_ref_section[:1000])
    else:
        st.error("KaynakÃ§a bÃ¶lÃ¼mÃ¼ (References/KaynakÃ§a) tespit
