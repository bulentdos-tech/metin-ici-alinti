import streamlit as st
import pandas as pd
import re
import fitz  # PyMuPDF
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” AkÄ±llÄ± AtÄ±f & KaynakÃ§a DenetÃ§isi")
st.markdown("Metin iÃ§i atÄ±flarÄ± soyadÄ± ve yÄ±l bazÄ±nda kaynakÃ§a ile eÅŸleÅŸtirir.")

uploaded_file = st.file_uploader("Analiz edilecek PDF'i yÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Dosya okunuyor ve temizleniyor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            # Metni alÄ±rken satÄ±r sonu tirelerini birleÅŸtir
            text = page.get_text("text")
            text = re.sub(r'-\s*\n', '', text) # SatÄ±r sonu tireleme (Ã–rn: 1041- 6080)
            full_text += text + " "
        doc.close()
        
        # Fazla boÅŸluklarÄ± temizle
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§ayÄ± AyÄ±r
    ref_keywords = [r'\bKaynakÃ§a\b', r'\bReferences\b', r'\bKAYNAKÃ‡A\b', r'\bREFERENCES\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text))
        if matches:
            split_index = matches[-1].start()
            break

    if split_index != -1:
        body_text = full_text[:split_index]
        references_text = full_text[split_index:]

        # 2. AtÄ±flarÄ± Yakala
        # (Yazar, 2021) veya Yazar (2021) veya Yazar et al. (2023)
        patterns = [
            r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+et\s+al\.)?)\s*\((\d{4})\)', # Metin iÃ§i
            r'\(([^)]+),\s*(\d{4})\)' # Parantez iÃ§i
        ]
        
        citations = []
        for p in patterns:
            for m in re.finditer(p, body_text):
                raw_yazar = m.group(1)
                yil = m.group(2)
                
                # SoyadlarÄ±nÄ± temizle (Bembenutty & Karabenick -> ['Bembenutty', 'Karabenick'])
                # Sadece bÃ¼yÃ¼k harfle baÅŸlayan kelimeleri soyadÄ± kabul et
                soyadi_listesi = re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+', raw_yazar)
                
                citations.append({
                    "tam_atif": f"{raw_yazar} ({yil})",
                    "soyadlar": soyadi_listesi,
                    "yil": yil
                })

        df_raw = pd.DataFrame(citations).drop_duplicates(subset=['tam_atif'])

        # 3. AkÄ±llÄ± KarÅŸÄ±laÅŸtÄ±rma
        results = []
        ref_lower = references_text.lower()

        for _, row in df_raw.iterrows():
            found = False
            # EÄŸer soyadlarÄ±ndan en az biri ve yÄ±l kaynakÃ§ada aynÄ± yerlerdeyse true dÃ¶n
            # Daha garanti olmasÄ± iÃ§in ilk soyadÄ± mutlaka kontrol et
            if row['soyadlar']:
                ana_soyad = row['soyadlar'][0].lower()
                yil = row['yil']
                
                # KaynakÃ§ada hem soyadÄ± hem yÄ±l geÃ§iyor mu?
                if ana_soyad in ref_lower and yil in ref_lower:
                    found = True
            
            results.append({
                "AtÄ±f": row['tam_atif'],
                "Durum": "âœ… KaynakÃ§ada Var" if found else "âŒ KaynakÃ§ada Yok",
                "Aranan SoyadÄ±": row['soyadlar'][0] if row['soyadlar'] else "BulunamadÄ±"
            })

        # 4. ArayÃ¼z
        df_res = pd.DataFrame(results)
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("AtÄ±f Listesi")
            st.dataframe(df_res, use_container_width=True)
            
        with col2:
            st.subheader("Hata Ã–zeti")
            errors = df_res[df_res['Durum'] == "âŒ KaynakÃ§ada Yok"]
            if not errors.empty:
                st.error(f"{len(errors)} AtÄ±f bulunamadÄ±!")
                st.write(errors['AtÄ±f'].unique())
            else:
                st.success("TÃ¼m atÄ±flar doÄŸrulandÄ±!")

    else:
        st.warning("KaynakÃ§a baÅŸlÄ±ÄŸÄ± bulunamadÄ±.")
