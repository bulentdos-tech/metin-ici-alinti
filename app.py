import streamlit as st
import pandas as pd
import re
import fitz
import io

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")

st.title("ğŸ” Profesyonel AtÄ±f DenetÃ§isi (Kesin SonuÃ§)")
st.markdown("Bu sÃ¼rÃ¼m, kaynakÃ§adaki eserleri **sadece metin gÃ¶vdesinde** arar. KaynakÃ§anÄ±n kendisini tarama dÄ±ÅŸÄ± bÄ±rakÄ±r.")

KARA_LISTE = ["march", "april", "university", "journal", "retrieved", "from", "doi", "http", "https", "pdf", "page", "january", "proceedings", "conference"]

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

if uploaded_file:
    with st.spinner('Dosya analiz ediliyor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            full_text += page.get_text("text") + " \n "
        doc.close()
        
        # Metin normalizasyonu (Gereksiz boÅŸluklarÄ± ve satÄ±r sonu kaymalarÄ±nÄ± temizler)
        full_text = re.sub(r'\s+', ' ', full_text)

    # 1. KaynakÃ§a BÃ¶lÃ¼mÃ¼nÃ¼ Tespit Et ve BÃ¶l
    # 'References' veya 'KaynakÃ§a' kelimesinin en son geÃ§tiÄŸi yeri bul (Ä°Ã§indekiler kÄ±smÄ±yla karÄ±ÅŸmamasÄ± iÃ§in)
    ref_keywords = [r'\bReferences\b', r'\bKaynakÃ§a\b', r'\bKAYNAKÃ‡A\b']
    split_index = -1
    for kw in ref_keywords:
        matches = list(re.finditer(kw, full_text, re.IGNORECASE))
        if matches:
            # En sondaki 'References' baÅŸlÄ±ÄŸÄ±nÄ± al
            split_index = matches[-1].start()
            break

    if split_index != -1:
        # --- KRÄ°TÄ°K AYRIM ---
        body_text = full_text[:split_index]  # Sadece metin (Arama burada yapÄ±lacak)
        raw_ref_section = full_text[split_index:] # Sadece kaynakÃ§a listesi
        
        # KaynakÃ§ayÄ± bloklara ayÄ±r (Yazar, A. (YÄ±l) formatÄ±na gÃ¶re)
        # Bu pattern 'SoyadÄ±, A.' veya 'SoyadÄ±, A. B.' ÅŸeklinde baÅŸlayan satÄ±rlarÄ± yakalar
        ref_pattern = r'(?<=\.\s)(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+,?\s+[A-Z]\.)'
        ref_blocks = [b.strip() for b in re.split(ref_pattern, raw_ref_section) if len(b.strip()) > 20]

        # --- ANALÄ°Z 1: METÄ°NDE VAR, KAYNAKÃ‡ADA YOK ---
        found_in_body = []
        # (Yazar, 2020) veya Yazar (2020)
        matches = re.findall(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        for auth, yr in matches:
            found_in_body.append({"auth": auth.strip(), "year": yr, "full": f"{auth} ({yr})"})

        missing_in_ref = []
        for cit in found_in_body:
            author_key = cit["auth"].split()[0].replace(',', '').lower()
            if any(word in author_key for word in KARA_LISTE): continue
            
            # KaynakÃ§a bloklarÄ± iÃ§inde bu yazar ve yÄ±lÄ± ara
            is_in_ref = any(author_key in block.lower() and cit["year"] in block for block in ref_blocks)
            if not is_in_ref:
                missing_in_ref.append({"Metindeki AtÄ±f": cit["full"]})

        df_missing_in_ref = pd.DataFrame(missing_in_ref).drop_duplicates()

        # --- ANALÄ°Z 2: KAYNAKÃ‡ADA VAR, METÄ°NDE YOK (Sizin sildiÄŸiniz kaynaklar burada Ã§Ä±kacak) ---
        unused_refs = []
        for block in ref_blocks:
            # BloÄŸun baÅŸÄ±ndaki SoyadÄ± ve ilk yÄ±lÄ± Ã§ek
            author_match = re.search(r'^([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)', block)
            year_match = re.search(r'(\d{4})', block)
            
            if author_match and year_match:
                author_surname = author_match.group(1)
                ref_year = year_match.group(1)
                
                # Ã–NEMLÄ°: Sadece body_text (metin gÃ¶vdesi) iÃ§inde yazar ve yÄ±lÄ± yan yana ara
                # Regex: Yazar isminden sonra makul bir mesafede yÄ±l gelmeli
                check_pattern = rf"{author_surname}.*?{ref_year}|{ref_year}.*?{author_surname}"
                is_cited = re.search(check_pattern, body_text, re.IGNORECASE)
                
                if not is_cited:
                    unused_refs.append({"Metinde AtÄ±fÄ± Bulunmayan Kaynak": block[:120] + "..."})

        df_unused_refs = pd.DataFrame(unused_refs)

        # --- GÃ–RSELLEÅTÄ°RME ---
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("âŒ KaynakÃ§ada Olmayan AtÄ±flar")
            if not df_missing_in_ref.empty:
                st.error(f"{len(df_missing_in_ref)} atÄ±f kaynakÃ§ada bulunamadÄ±.")
                st.table(df_missing_in_ref)
            else:
                st.success("TÃ¼m atÄ±flar kaynakÃ§ada mevcut.")

        with col2:
            st.subheader("âš ï¸ Metinde AtÄ±fÄ± Olmayanlar")
            if not df_unused_refs.empty:
                st.warning(f"{len(df_unused_refs)} kaynak metinde hiÃ§ geÃ§miyor.")
                st.table(df_unused_refs)
            else:
                st.success("KaynakÃ§adaki tÃ¼m eserlere atÄ±f yapÄ±lmÄ±ÅŸ.")

        # Excel Raporu
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            if not df_missing_in_ref.empty:
                df_missing_in_ref.to_excel(writer, sheet_name='Eksik Kaynaklar', index=False)
            if not df_unused_refs.empty:
                df_unused_refs.to_excel(writer, sheet_name='Metinde AtÄ±fÄ± Yok', index=False)
        
        st.divider()
        st.download_button("ğŸ“¥ Hata Raporunu Ä°ndir", output.getvalue(), "denetim_raporu.xlsx")

    else:
        st.error("KaynakÃ§a/References baÅŸlÄ±ÄŸÄ± bulunamadÄ±.")
