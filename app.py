import streamlit as st
import pandas as pd
import re
import fitz

st.set_page_config(page_title="Akademik DenetÃ§i Pro", layout="wide")
st.title("ğŸ” GeliÅŸmiÅŸ AtÄ±f & KaynakÃ§a DenetÃ§isi")

uploaded_file = st.file_uploader("PDF DosyanÄ±zÄ± YÃ¼kleyin", type="pdf")

def temizle(text):
    # PDF temizleme: Heceleme ve gereksiz boÅŸluklarÄ± onarÄ±r
    text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
    return " ".join(text.split())

if uploaded_file:
    with st.spinner('Derin analiz yapÄ±lÄ±yor...'):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        for page in doc:
            full_text += page.get_text("text") + "\n"
        doc.close()
        full_text = temizle(full_text)

    # 1. BÃ–LÃœM: KAYNAKÃ‡AYI AYIR
    # En sondaki References baÅŸlÄ±ÄŸÄ±nÄ± bulur
    ref_matches = list(re.finditer(r'\b(References|KaynakÃ§a|KAYNAKÃ‡A)\b', full_text, re.IGNORECASE))
    
    if ref_matches:
        split_point = ref_matches[-1].start()
        body_text = full_text[:split_point]
        ref_section = full_text[split_point:]

        # 2. BÃ–LÃœM: METÄ°N Ä°Ã‡Ä° ATIFLARI YAKALA (GeliÅŸmiÅŸ Regex)
        # Biggs & Tang (2011) veya (Baidoo-Anu et al., 2023) gibi yapÄ±larÄ± bulur
        # 1900-2099 arasÄ± yÄ±llarÄ± ve opsiyonel a,b harflerini yakalar
        body_cites = re.findall(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ&, ]+(?:\s+et\s+al\.)?)\s*\((\d{4}[a-z]?)\)', body_text)
        
        # 3. BÃ–LÃœM: KAYNAKÃ‡AYI ESERLERE AYIR (Blok MantÄ±ÄŸÄ±)
        # Genellikle APA formatÄ±nda her yeni eser yeni bir satÄ±rda Soyad, A. formatÄ±yla baÅŸlar
        ref_blocks = re.split(r'\s{2,}(?=[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+,?\s+[A-Z]\.)', ref_section)
        
        errors = []

        # --- KONTROL 1: KAYNAKÃ‡ADA VAR -> METÄ°NDE YOK MU? (Sildikleriniz) ---
        for block in ref_blocks:
            if len(block) < 15: continue
            # Blok iÃ§indeki ilk yazarÄ± ve yÄ±lÄ± bul
            auth_match = re.search(r'^([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)', block.strip())
            year_match = re.search(r'\((\d{4})\)', block)
            
            if auth_match and year_match:
                auth = auth_match.group(1)
                year = year_match.group(1)
                # Metinde bu soyad ve yÄ±l bir arada geÃ§iyor mu?
                if not re.search(rf"\b{auth}\b.*?{year}", body_text, re.IGNORECASE):
                    errors.append({
                        "Eser": f"{auth} ({year})",
                        "Hata TÃ¼rÃ¼": "âš ï¸ Metinde AtÄ±fÄ± Yok",
                        "AÃ§Ä±klama": "Bu kaynak listede var ama metin gÃ¶vdesinde bulunamadÄ±."
                    })

        # --- KONTROL 2: METÄ°NDE VAR -> KAYNAKÃ‡ADA YOK MU? (Unutulanlar) ---
        for b_auth, b_year in body_cites:
            # AtÄ±ftaki ilk soyadÄ± temizleyerek al
            b_clean = b_auth.replace(" et al.", "").replace("&", " ").replace(",", " ").split()[0].strip()
            if b_clean.lower() in ["table", "figure", "appendix", "chapter"]: continue
            
            # KaynakÃ§a iÃ§inde bu soyad ve yÄ±lÄ± ara
            if not re.search(rf"\b{b_clean}\b.*?{b_year}", ref_section, re.IGNORECASE):
                errors.append({
                    "Eser": f"{b_auth.strip()} ({b_year})",
                    "Hata TÃ¼rÃ¼": "âŒ KaynakÃ§ada Yok",
                    "AÃ§Ä±klama": "Metinde bu esere atÄ±f yapÄ±lmÄ±ÅŸ ancak kaynakÃ§a listesine eklenmemiÅŸ."
                })

        # SONUÃ‡LARI GÃ–STER
        st.divider()
        df_errors = pd.DataFrame(errors).drop_duplicates()
        
        if not df_errors.empty:
            st.error(f"ğŸ” Toplam {len(df_errors)} tutarsÄ±zlÄ±k tespit edildi:")
            st.table(df_errors)
        else:
            st.success("âœ… Tebrikler! Metin ve KaynakÃ§a tam uyumlu gÃ¶rÃ¼nÃ¼yor.")
    else:
        st.warning("KaynakÃ§a (References) bÃ¶lÃ¼mÃ¼ tespit edilemedi. LÃ¼tfen baÅŸlÄ±ÄŸÄ± kontrol edin.")
